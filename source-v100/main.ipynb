{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project MGS (Medical Graphing Study)\n",
    "\n",
    "This is the first version of project MGS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version:  1.26.2\n",
      "OpenCV version:  4.9.0\n",
      "Pandas version:  2.2.2\n",
      "CUDA Available:  True\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Please check if this CUDA is available unless your device does not support CUDA\n",
      "Uncommect the command to install GPU if your device does support CUDA\n",
      "DICOM Version:  2.4.4\n"
     ]
    }
   ],
   "source": [
    "# numerical python library needed for mathematical operations\n",
    "import numpy as NumPy\n",
    "print(\"numpy version: \", NumPy.__version__)\n",
    "# this library is useful for processing images\n",
    "import cv2 as OpenCV\n",
    "print(\"OpenCV version: \", OpenCV.__version__)\n",
    "# we will be storing our data in a dataframe\n",
    "import pandas as Pandas\n",
    "print(\"Pandas version: \", Pandas.__version__)\n",
    "from matplotlib import pyplot as PyPlot\n",
    "\n",
    "import os # useful for file handling operations\n",
    "# pyTorch is a common library for creating neural networks and AI applications\n",
    "#%pip install torch\n",
    "# pyTorch dependency\n",
    "#%pip install torchvision\n",
    "# pyTorch dependency\n",
    "#%pip install torchaudio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# This command installs the GPU version of PyTorch\n",
    "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "#print(\"PyTorch version: \", PyTorch.__version__)\n",
    "print(\"CUDA Available: \", torch.cuda.is_available())\n",
    "print(\"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\")\n",
    "print(\"Please check if this CUDA is available unless your device does not support CUDA\")\n",
    "print(\"Uncommect the command to install GPU if your device does support CUDA\")\n",
    "\n",
    "# The images we receive are in DICOM format, therefore, we use pyDICOM\n",
    "\n",
    "import pydicom as DICOM\n",
    "print(\"DICOM Version: \", DICOM.__version__)\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DICOM to Numpy Array\n",
    "Original by Esa Anjum (https://stackoverflow.com/a/74886257), Modified for our use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicom_to_numpy(ds, Show = False):\n",
    "\t\tDCM_Img = ds\n",
    "\t\timage_data = DCM_Img.pixel_array\n",
    "\t\t# Get slope and intercept values (assuming they exist in the DICOM data)\n",
    "\t\tslope = DCM_Img.RescaleSlope if hasattr(DCM_Img, 'RescaleSlope') else 1.0\n",
    "\t\tintercept = DCM_Img.RescaleIntercept if hasattr(DCM_Img, 'RescaleIntercept') else 0.0\n",
    "\t\t\n",
    "\t\tscaled_image = image_data * slope + intercept\n",
    "\t\tif Show:\n",
    "\t\t\tOpenCV.imshow(scaled_image)\n",
    "\t\t\tOpenCV.waitKey(0)\n",
    "\n",
    "\t\treturn scaled_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step One: Image Acquisition\n",
    "\n",
    "We are primarily using the [Cancer Imaging Archive (LIDC-IDRI) Dataset](https://www.cancerimagingarchive.net/collection/lidc-idri/) for our project. This dataset provides the following information that we will be using for the project:\n",
    "1. Images\n",
    "2. Metadata\n",
    "3. Nodule Counts\n",
    "4. Patient Diagnoses\n",
    "\n",
    "## Data Acquisition and Usage\n",
    "1. Load list of patients -> ```Patients: Dataframe```\n",
    "2. Load patient diagnoses -> ```Patients: Dataframe```\n",
    "3. Load images from top -> ```Patients: Dataframe``` (Location of Top Views in ```TopImages```) and ```TopImages: List of NumPy Arrays```\n",
    "4. Load images from side -> ```Patients: Dataframe``` (Location of Side Views in ```SideImages```) and ```SideImages: List of NumPy Arrays```\n",
    "5. Load images from front -> ```Patients: Dataframe``` (Location of Front Views in ```FrontImages```) and ```FrontImages: List of NumPy Arrays```\n",
    "6. Metadata -> ```Patients: Dataframe```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Acquisition Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadImage(Location:os.path, Show:bool = False) -> OpenCV.Mat:\n",
    "\tImage = DICOM.dcmread(Location)\n",
    "\tImage = dicom_to_numpy(Image)\n",
    "\t\n",
    "\tif Show:\n",
    "\t\tOpenCV.imshow(\"Images\", Image)\n",
    "\t\tOpenCV.waitKey(0)\n",
    "\n",
    "\treturn OpenCV.Mat(Image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Pandas.DataFrame()\n",
    "number_of_patients = 6  # Adjust this to the desired number of IDs\n",
    "patient_list = [\"LIDC-IDRI-\" + f\"{i:04}\" for i in range(1, number_of_patients + 1)]\n",
    "diagnoses = Pandas.read_excel('./LIDC-META/tcia-diagnosis-data-2012-04-20.xls')\n",
    "complete_diagnoses = []\n",
    "for patient in patient_list:\n",
    "\ttry:\n",
    "\t\tcomplete_diagnoses.append(diagnoses['Diagnosis'][\n",
    "\t\t\t(diagnoses['Patient ID'])\n",
    "\t\t\t[\n",
    "\t\t\t\tdiagnoses['Patient ID'] == patient\n",
    "\t\t\t].index[0]\n",
    "\t\t\t])\n",
    "\texcept:\n",
    "\t\tcomplete_diagnoses.append(0)\n",
    "\n",
    "complete_diagnoses = Pandas.Series(complete_diagnoses)\n",
    "\n",
    "# add directories to all files in a 'files' list\n",
    "location = './LIDC-IDRI'\n",
    "patients = []\n",
    "for item in sorted(os.listdir(location)):  # Sort patient folders alphabetically\n",
    "\titem_path = os.path.join(location, item)\n",
    "\tif os.path.isdir(item_path):\n",
    "\t\tpatient_files = []\n",
    "\t\tfor dirpath, _, filenames in os.walk(item_path):  # Efficiently traverse folders\n",
    "\t\t\tfor filename in filenames:\n",
    "\t\t\t\tif not filename.endswith(\".xml\"):\n",
    "\t\t\t\t\tfilepath = os.path.join(dirpath, filename)\n",
    "\t\t\t\t\tpatient_files.append(filepath)\n",
    "\t\tpatients.append(patient_files)\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing\n",
    "## Parameters\n",
    "Adjustable to suit your needs and for A/B testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "HistogramAlphaScaling = 1000\n",
    "GaussianKernel = (3, 3)\n",
    "GaussianSigma = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "### Image Normalisation\n",
    "\n",
    "The contrast in the image is too high or too low in most cases, we would prefer to have a standard contrast throughout the dataset, this is why we are applying a histogram normalisation method to make the image data more readable for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HistNormalize(image:OpenCV.Mat) -> None:\n",
    "    OpenCV.normalize(image, image, HistogramAlphaScaling)\n",
    "    image = OpenCV.GaussianBlur(image, GaussianKernel, GaussianSigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Dataset\n",
    "\n",
    "We split our dataset into a random train/test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, labels, test_size=0.2):\n",
    "\t\"\"\"\n",
    "\tSplits data and labels into training and testing sets manually.\n",
    "\n",
    "\tArgs:\n",
    "\t\tdata: A list or NumPy array containing the data points.\n",
    "\t\tlabels: A list or NumPy array containing the corresponding labels.\n",
    "\t\ttest_size: The proportion of data to be used for the testing set (default: 0.2).\n",
    "\n",
    "\tReturns:\n",
    "\t\tA tuple containing four elements:\n",
    "\t\t\t- X_train: The training data.\n",
    "\t\t\t- X_test: The testing data.\n",
    "\t\t\t- y_train: The training labels.\n",
    "\t\t\t- y_test: The testing labels.\n",
    "\t\"\"\"\n",
    "\tdata_length = len(data)\n",
    "\ttest_index = int(data_length * test_size)\n",
    "\n",
    "\t# Shuffle data and labels together for balanced split\n",
    "\tcombined = list(zip(data, labels))\n",
    "\trandom.shuffle(combined)\n",
    "\tdata, labels = zip(*combined)\n",
    "\n",
    "\tX_train = data[:test_index]\n",
    "\tX_test = data[test_index:]\n",
    "\ty_train = labels[:test_index]\n",
    "\ty_test = labels[test_index:]\n",
    "\n",
    "\treturn X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = patients\n",
    "y = diagnoses['Diagnosis']\n",
    "\n",
    "test_size = 0.5\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Data Loader\n",
    "We use the image acquisition and processing algos we wrote before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self, pat, dia):\n",
    "        self.patients = pat\n",
    "        self.diagnoses = dia\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.diagnoses)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = []\n",
    "        diag = []\n",
    "\n",
    "        for loc in self.patients[idx]:\n",
    "            img = LoadImage(loc)\n",
    "            HistNormalize(img)\n",
    "            img = OpenCV.cvtColor(img, OpenCV.COLOR_GRAY2RGB)\n",
    "\n",
    "\n",
    "            # Get image data size\n",
    "            data_size = NumPy.product(img.shape)\n",
    "            # Convert to float version of NumPy array\n",
    "            img = img.astype(NumPy.float32)\n",
    "\n",
    "            \n",
    "            image.append(img)\n",
    "            diag.append(self.diagnoses[idx])\n",
    "            \n",
    "        return image, diag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembling our CNN\n",
    "\n",
    "We have chosen the VGG16 architecture after careful consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "\tdef __init__(self, num_classes=1000):  # Modify num_classes for your task\n",
    "\t\tsuper(VGG16, self).__init__()\n",
    "\t\tself.block_1 = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\t\t)\n",
    "\t\tself.block_2 = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\t\t)\n",
    "\t\tself.block_3 = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\t\t)\n",
    "\n",
    "\t\tin_features = 256 * 7 * 7\n",
    "\t\tself.fc = nn.Linear(in_features=in_features, out_features=num_classes)\n",
    "\t\t\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# Block 1\n",
    "\t\tx = self.block_1(x)\n",
    "\n",
    "\t\t# Block 2\n",
    "\t\tx = self.block_2(x)\n",
    "\n",
    "\t\t# Block 3\n",
    "\t\tx = self.block_3(x)\n",
    "\t\t# ... (rest of the architecture, if any)\n",
    "\n",
    "\t\t# Final output layer (modify for your task)\n",
    "\t\tx = self.fc(x)  # Example fully-connected layer (replace with your output layer)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) d:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:94: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<1,-1,-1>,struct cv::impl::A0x59191d0d::Set<3,4,-1>,struct cv::impl::A0x59191d0d::Set<0,2,5>,4>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Unsupported depth of input image:\n>     'VDepth::contains(depth)'\n> where\n>     'depth' is 6 (CV_64F)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[529], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      7\u001b[0m   \u001b[38;5;66;03m# Create a new dataloader for each epoch (optional for shuffling)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m   custom_dataloader \u001b[38;5;241m=\u001b[39m CustomDataLoader(X_train, y_train)\n\u001b[1;32m---> 10\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcustom_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Check if images is a list (multiple images per patient)\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcombined\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[1;32mIn[527], line 16\u001b[0m, in \u001b[0;36mCustomDataLoader.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     14\u001b[0m img \u001b[38;5;241m=\u001b[39m LoadImage(loc)\n\u001b[0;32m     15\u001b[0m HistNormalize(img)\n\u001b[1;32m---> 16\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mOpenCV\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOpenCV\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_GRAY2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Get image data size\u001b[39;00m\n\u001b[0;32m     20\u001b[0m data_size \u001b[38;5;241m=\u001b[39m NumPy\u001b[38;5;241m.\u001b[39mproduct(img\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) d:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:94: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<1,-1,-1>,struct cv::impl::A0x59191d0d::Set<3,4,-1>,struct cv::impl::A0x59191d0d::Set<0,2,5>,4>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Unsupported depth of input image:\n>     'VDepth::contains(depth)'\n> where\n>     'depth' is 6 (CV_64F)\n"
     ]
    }
   ],
   "source": [
    "model = VGG16()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  # Create a new dataloader for each epoch (optional for shuffling)\n",
    "  custom_dataloader = CustomDataLoader(X_train, y_train)\n",
    "\n",
    "  for i, (images, labels) in enumerate(custom_dataloader):\n",
    "    # Check if images is a list (multiple images per patient)\n",
    "    if isinstance(images, list):\n",
    "      combined = []\n",
    "      init_shape = images[0].shape\n",
    "      for image in images:\n",
    "        #image = image.numpy()\n",
    "        image = torch.from_numpy(image)\n",
    "        if image.shape == init_shape:\n",
    "          combined.append(image)\n",
    "      # Combine images into a single tensor (e.g., using torch.cat)\n",
    "      images = torch.cat(combined, dim=0)  # Concatenate along batch dimension (0)\n",
    "    \n",
    "    images = images.unsqueeze(0)  # Add a batch dimension\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print information (optional)\n",
    "    if i % 100 == 0:\n",
    "      print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(custom_dataloader)}], Loss: {loss.item():.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
